# LLM Agent Framework for Scientific Research / ç§‘ç ”LLMæ™ºèƒ½ä½“æ¡†æ¶

[English](#english) | [ä¸­æ–‡](#chinese)

---

## <a id="english"></a>English

### Overview

A lightweight, flexible framework for building custom LLM agents for scientific research. This framework provides an intuitive API for creating agents with custom tools, organizing multi-agent collaboration, and integrating with any LLM API endpoint.

### Key Features

- ğŸ› ï¸ **Flexible Tool System**: Easy-to-create custom tools with built-in utilities
- ğŸ¤– **Multi-Agent Orchestration**: Advanced collaboration patterns (Sequential, Parallel, Hierarchical)
- ğŸ”Œ **API-Agnostic**: Works with any LLM API (OpenAI, Claude, custom endpoints)
- ğŸ¨ **Modern GUI**: Streamlit-based interactive interface
- ğŸ’¾ **Persistent Storage**: Supabase integration for conversation history and analytics
- ğŸ“Š **Research-Oriented**: Built-in tools for scientific computing, data analysis, and literature search
- ğŸ“ **Extensive Documentation**: Detailed annotations and examples

### Architecture

```
python-agent-framework/
â”œâ”€â”€ core/                  # Core framework components
â”‚   â”œâ”€â”€ agent.py          # Base agent class
â”‚   â”œâ”€â”€ tool.py           # Tool system
â”‚   â”œâ”€â”€ llm_client.py     # LLM API integration
â”‚   â””â”€â”€ orchestrator.py   # Multi-agent collaboration
â”œâ”€â”€ tools/                 # Built-in tools
â”‚   â”œâ”€â”€ base_tools.py     # Calculator, web search, etc.
â”‚   â”œâ”€â”€ research_tools.py # Scientific computing tools
â”‚   â””â”€â”€ data_tools.py     # Data analysis tools
â”œâ”€â”€ gui/                   # Streamlit GUI
â”‚   â””â”€â”€ app.py            # Main interface
â”œâ”€â”€ examples/              # Usage examples
â”œâ”€â”€ utils/                 # Utilities
â””â”€â”€ config/                # Configuration
```

### Quick Start

1. **Installation**
```bash
cd python-agent-framework
pip install -r requirements.txt
```

2. **Configure Environment**
```bash
cp .env.example .env
# Edit .env with your API keys
```

3. **Run GUI**
```bash
streamlit run gui/app.py
```

4. **Basic Usage**
```python
from core.agent import Agent
from core.llm_client import LLMClient
from tools.base_tools import CalculatorTool

# Initialize LLM client
client = LLMClient(
    api_url="https://api.openai.com/v1/chat/completions",
    api_key="your-key",
    model="gpt-4"
)

# Create agent with tools
agent = Agent(
    name="ResearchAssistant",
    llm_client=client,
    tools=[CalculatorTool()],
    system_prompt="You are a helpful research assistant."
)

# Run task
response = agent.run("Calculate the square root of 144")
print(response)
```

### Creating Custom Tools

```python
from core.tool import Tool
from typing import Dict, Any

class MyCustomTool(Tool):
    """
    Custom tool example.
    è‡ªå®šä¹‰å·¥å…·ç¤ºä¾‹ã€‚
    """
    def __init__(self):
        super().__init__(
            name="my_tool",
            description="Description of what this tool does"
        )

    def execute(self, **kwargs) -> Dict[str, Any]:
        """
        Execute the tool logic.
        æ‰§è¡Œå·¥å…·é€»è¾‘ã€‚
        """
        # Your tool logic here
        result = {"status": "success", "data": "result"}
        return result
```

### Multi-Agent Collaboration

```python
from core.orchestrator import SequentialOrchestrator, ParallelOrchestrator

# Create multiple agents with different specializations
researcher = Agent(
    name="Researcher",
    llm_client=client,
    tools=[...],
    system_prompt="You are a research specialist."
)

analyst = Agent(
    name="Analyst",
    llm_client=client,
    tools=[...],
    system_prompt="You are a data analyst."
)

# Sequential orchestration (agents work one after another)
seq_orchestrator = SequentialOrchestrator([researcher, analyst])
result = seq_orchestrator.run("Research quantum computing and analyze trends")

# Parallel orchestration (agents work simultaneously)
par_orchestrator = ParallelOrchestrator([agent1, agent2, agent3])
results = par_orchestrator.run("Analyze this dataset from different angles")
```

### Built-in Tools

- **CalculatorTool**: Mathematical computations using Python's math library
- **WebSearchTool**: Internet search capabilities (requires API key)
- **FileIOTool**: File reading and writing operations
- **PythonREPLTool**: Execute Python code safely
- **ScientificComputeTool**: NumPy/SciPy integration for scientific computing
- **DataAnalysisTool**: Pandas-based data analysis and statistics
- **VisualizationTool**: Matplotlib/Plotly plotting and visualization
- **LiteratureSearchTool**: Search scientific papers and publications

### Advanced Features

#### Memory and Context Management
```python
agent = Agent(
    name="Assistant",
    llm_client=client,
    tools=[...],
    memory_enabled=True,  # Enable conversation memory
    max_memory_tokens=4000
)
```

#### Custom Orchestration Patterns
```python
from core.orchestrator import CustomOrchestrator

class MyOrchestrator(CustomOrchestrator):
    def orchestrate(self, task: str):
        # Implement your custom orchestration logic
        pass
```

#### Integration with Supabase
```python
from utils.storage import SupabaseStorage

storage = SupabaseStorage()
# Store conversation history
storage.save_conversation(agent_name, messages)
# Retrieve analytics
analytics = storage.get_analytics()
```

---

## <a id="chinese"></a>ä¸­æ–‡

### æ¦‚è¿°

ä¸€ä¸ªè½»é‡çº§ã€çµæ´»çš„ç§‘ç ”LLMæ™ºèƒ½ä½“æ¡†æ¶ã€‚æœ¬æ¡†æ¶æä¾›ç›´è§‚çš„APIç”¨äºåˆ›å»ºå¸¦æœ‰è‡ªå®šä¹‰å·¥å…·çš„æ™ºèƒ½ä½“ã€ç»„ç»‡å¤šæ™ºèƒ½ä½“åä½œï¼Œå¹¶é›†æˆä»»ä½•LLM APIç«¯ç‚¹ã€‚

### æ ¸å¿ƒç‰¹æ€§

- ğŸ› ï¸ **çµæ´»çš„å·¥å…·ç³»ç»Ÿ**ï¼šæ˜“äºåˆ›å»ºè‡ªå®šä¹‰å·¥å…·ï¼ŒåŒ…å«å†…ç½®å®ç”¨å·¥å…·
- ğŸ¤– **å¤šæ™ºèƒ½ä½“ç¼–æ’**ï¼šé«˜çº§åä½œæ¨¡å¼ï¼ˆé¡ºåºã€å¹¶è¡Œã€å±‚çº§ï¼‰
- ğŸ”Œ **APIæ— å…³**ï¼šæ”¯æŒä»»ä½•LLM APIï¼ˆOpenAIã€Claudeã€è‡ªå®šä¹‰ç«¯ç‚¹ï¼‰
- ğŸ¨ **ç°ä»£åŒ–GUI**ï¼šåŸºäºStreamlitçš„äº¤äº’ç•Œé¢
- ğŸ’¾ **æŒä¹…åŒ–å­˜å‚¨**ï¼šSupabaseé›†æˆï¼Œç”¨äºå¯¹è¯å†å²å’Œåˆ†æ
- ğŸ“Š **é¢å‘ç§‘ç ”**ï¼šå†…ç½®ç§‘å­¦è®¡ç®—ã€æ•°æ®åˆ†æå’Œæ–‡çŒ®æ£€ç´¢å·¥å…·
- ğŸ“ **è¯¦å°½æ–‡æ¡£**ï¼šè¯¦ç»†æ³¨é‡Šå’Œç¤ºä¾‹

### ç³»ç»Ÿæ¶æ„

æœ¬æ¡†æ¶é‡‡ç”¨æ¨¡å—åŒ–è®¾è®¡ï¼Œæ ¸å¿ƒç»„ä»¶åŒ…æ‹¬ï¼š
- **Agentï¼ˆæ™ºèƒ½ä½“ï¼‰**ï¼šæ‰§è¡Œä»»åŠ¡çš„åŸºæœ¬å•å…ƒ
- **Toolï¼ˆå·¥å…·ï¼‰**ï¼šæ™ºèƒ½ä½“å¯è°ƒç”¨çš„åŠŸèƒ½æ¨¡å—
- **LLMClientï¼ˆLLMå®¢æˆ·ç«¯ï¼‰**ï¼šä¸å„ç§LLM APIé€šä¿¡
- **Orchestratorï¼ˆç¼–æ’å™¨ï¼‰**ï¼šç®¡ç†å¤šæ™ºèƒ½ä½“åä½œ

### å¿«é€Ÿå¼€å§‹

1. **å®‰è£…ä¾èµ–**
```bash
cd python-agent-framework
pip install -r requirements.txt
```

2. **é…ç½®ç¯å¢ƒ**
```bash
cp .env.example .env
# ç¼–è¾‘.envæ–‡ä»¶ï¼Œå¡«å…¥æ‚¨çš„APIå¯†é’¥
```

3. **è¿è¡ŒGUIç•Œé¢**
```bash
streamlit run gui/app.py
```

4. **åŸºç¡€ç”¨æ³•**
```python
from core.agent import Agent
from core.llm_client import LLMClient
from tools.base_tools import CalculatorTool

# åˆå§‹åŒ–LLMå®¢æˆ·ç«¯
client = LLMClient(
    api_url="https://api.openai.com/v1/chat/completions",
    api_key="your-key",
    model="gpt-4"
)

# åˆ›å»ºå¸¦å·¥å…·çš„æ™ºèƒ½ä½“
agent = Agent(
    name="ç ”ç©¶åŠ©æ‰‹",
    llm_client=client,
    tools=[CalculatorTool()],
    system_prompt="ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ç ”ç©¶åŠ©æ‰‹ã€‚"
)

# æ‰§è¡Œä»»åŠ¡
response = agent.run("è®¡ç®—144çš„å¹³æ–¹æ ¹")
print(response)
```

### åˆ›å»ºè‡ªå®šä¹‰å·¥å…·

```python
from core.tool import Tool
from typing import Dict, Any

class MyCustomTool(Tool):
    """
    è‡ªå®šä¹‰å·¥å…·ç¤ºä¾‹ã€‚
    Custom tool example.
    """
    def __init__(self):
        super().__init__(
            name="my_tool",
            description="æè¿°æ­¤å·¥å…·çš„åŠŸèƒ½"
        )

    def execute(self, **kwargs) -> Dict[str, Any]:
        """
        æ‰§è¡Œå·¥å…·é€»è¾‘ã€‚
        Execute the tool logic.
        """
        # åœ¨è¿™é‡Œå®ç°æ‚¨çš„å·¥å…·é€»è¾‘
        result = {"status": "success", "data": "ç»“æœ"}
        return result
```

### å¤šæ™ºèƒ½ä½“åä½œ

```python
from core.orchestrator import SequentialOrchestrator, ParallelOrchestrator

# åˆ›å»ºå…·æœ‰ä¸åŒä¸“é•¿çš„å¤šä¸ªæ™ºèƒ½ä½“
researcher = Agent(
    name="ç ”ç©¶å‘˜",
    llm_client=client,
    tools=[...],
    system_prompt="ä½ æ˜¯ä¸€åç ”ç©¶ä¸“å®¶ã€‚"
)

analyst = Agent(
    name="åˆ†æå¸ˆ",
    llm_client=client,
    tools=[...],
    system_prompt="ä½ æ˜¯ä¸€åæ•°æ®åˆ†æå¸ˆã€‚"
)

# é¡ºåºç¼–æ’ï¼ˆæ™ºèƒ½ä½“ä¾æ¬¡å·¥ä½œï¼‰
seq_orchestrator = SequentialOrchestrator([researcher, analyst])
result = seq_orchestrator.run("ç ”ç©¶é‡å­è®¡ç®—å¹¶åˆ†æè¶‹åŠ¿")

# å¹¶è¡Œç¼–æ’ï¼ˆæ™ºèƒ½ä½“åŒæ—¶å·¥ä½œï¼‰
par_orchestrator = ParallelOrchestrator([agent1, agent2, agent3])
results = par_orchestrator.run("ä»ä¸åŒè§’åº¦åˆ†ææ­¤æ•°æ®é›†")
```

### å†…ç½®å·¥å…·

- **è®¡ç®—å™¨å·¥å…·**ï¼šä½¿ç”¨Python mathåº“è¿›è¡Œæ•°å­¦è®¡ç®—
- **ç½‘ç»œæœç´¢å·¥å…·**ï¼šäº’è”ç½‘æœç´¢èƒ½åŠ›ï¼ˆéœ€è¦APIå¯†é’¥ï¼‰
- **æ–‡ä»¶æ“ä½œå·¥å…·**ï¼šæ–‡ä»¶è¯»å†™æ“ä½œ
- **Pythonæ‰§è¡Œå™¨**ï¼šå®‰å…¨æ‰§è¡ŒPythonä»£ç 
- **ç§‘å­¦è®¡ç®—å·¥å…·**ï¼šNumPy/SciPyé›†æˆçš„ç§‘å­¦è®¡ç®—
- **æ•°æ®åˆ†æå·¥å…·**ï¼šåŸºäºPandasçš„æ•°æ®åˆ†æå’Œç»Ÿè®¡
- **å¯è§†åŒ–å·¥å…·**ï¼šMatplotlib/Plotlyç»˜å›¾å’Œå¯è§†åŒ–
- **æ–‡çŒ®æ£€ç´¢å·¥å…·**ï¼šæœç´¢ç§‘å­¦è®ºæ–‡å’Œå‡ºç‰ˆç‰©

### é«˜çº§åŠŸèƒ½

#### è®°å¿†ä¸ä¸Šä¸‹æ–‡ç®¡ç†
```python
agent = Agent(
    name="åŠ©æ‰‹",
    llm_client=client,
    tools=[...],
    memory_enabled=True,  # å¯ç”¨å¯¹è¯è®°å¿†
    max_memory_tokens=4000
)
```

#### è‡ªå®šä¹‰ç¼–æ’æ¨¡å¼
```python
from core.orchestrator import CustomOrchestrator

class MyOrchestrator(CustomOrchestrator):
    def orchestrate(self, task: str):
        # å®ç°æ‚¨çš„è‡ªå®šä¹‰ç¼–æ’é€»è¾‘
        pass
```

#### ä¸Supabaseé›†æˆ
```python
from utils.storage import SupabaseStorage

storage = SupabaseStorage()
# å­˜å‚¨å¯¹è¯å†å²
storage.save_conversation(agent_name, messages)
# æ£€ç´¢åˆ†ææ•°æ®
analytics = storage.get_analytics()
```

### ä½¿ç”¨åœºæ™¯

1. **ç§‘å­¦æ–‡çŒ®ç»¼è¿°**ï¼šè‡ªåŠ¨æœç´¢ã€åˆ†æå’Œæ€»ç»“ç§‘ç ”è®ºæ–‡
2. **æ•°æ®åˆ†æå·¥ä½œæµ**ï¼šå¤šæ­¥éª¤æ•°æ®å¤„ç†å’Œå¯è§†åŒ–
3. **å®éªŒè®¾è®¡åŠ©æ‰‹**ï¼šååŠ©è®¾è®¡å’Œä¼˜åŒ–å®éªŒæ–¹æ¡ˆ
4. **ä»£ç ç”Ÿæˆä¸è°ƒè¯•**ï¼šç”Ÿæˆç§‘ç ”ä»£ç å¹¶è¿›è¡Œæµ‹è¯•
5. **çŸ¥è¯†å›¾è°±æ„å»º**ï¼šä»æ–‡çŒ®ä¸­æå–å’Œç»„ç»‡çŸ¥è¯†

### è®¸å¯è¯ / License

MIT License

### è´¡çŒ® / Contributing

æ¬¢è¿è´¡çŒ®ä»£ç ã€æŠ¥å‘Šé—®é¢˜æˆ–æå‡ºæ–°åŠŸèƒ½å»ºè®®ï¼
Contributions, issues, and feature requests are welcome!

### æ”¯æŒ / Support

å¦‚æœ‰é—®é¢˜ï¼Œè¯·åˆ›å»ºIssueæˆ–æŸ¥çœ‹æ–‡æ¡£ã€‚
For questions, please create an issue or check the documentation.
